---
layout: default
---
<img class="profile-picture" src="imgs/me.jpg">

I am a PhD candidate in Computer Science in the Stanford NLP group. My research focuses on understanding and improving the social outcomes of NLP technologies, such as addressing anthropomorphism, social biases, and other implicit perceptions. I am advised by <a href="https://web.stanford.edu/~jurafsky">Dan Jurafsky</a> and supported by the Knight-Hennessy Scholarship and the NSF Graduate Research Fellowship. 

Previously, I did my undergraduate at Caltech, where I double-majored in computer science and history. I've also spent time at Microsoft Research (on the FATE team with Alexandra Olteanu and Su Lin Blodgett, and with [Adam Kalai](https://kal.ai/)) and DeepMind.

<!-- My work aims to mitigate algorithmic harms from language technologies and reveal the implicit norms that shape their development -->

### Contact
My email is myra [at] cs [dot] stanford [dot] edu.

### Updates
**May 2025**: Our work on [social sycophancy](https://arxiv.org/pdf/2505.13995) is featured in [MIT Technology Review](https://www.technologyreview.com/2025/05/30/1117551/this-benchmark-used-reddits-aita-to-test-how-much-ai-models-suck-up-to-us/)! 

**May 2025**: Two papers on [measuring](https://www.arxiv.org/pdf/2502.13259) and [mitigating](https://arxiv.org/pdf/2502.14019) anthropomorphic LLM outputs accepted to ACL 2025.

**April 2025**: Our paper on [Using metaphors to understand public perceptions of AI](https://www.arxiv.org/pdf/2501.18045) accepted to FAccT 2025.

**October 2024**: Attending [AIES](https://www.aies-conference.com/2024/). 

**October 2024**: ["I Am the One and Only, Your Cyber BFF": Understanding the Impact of GenAI Requires Understanding the Impact of Anthropomorphic AI](https://arxiv.org/abs/2410.08526).  
