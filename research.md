## Relevant Publications

1. Myra Cheng, Esin Durmus, and Dan Jurafsky. Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models. ACL 2023.
[[paper](https://arxiv.org/pdf/2108.11056.pdf)]
**Won the Social Impact Award at ACL 2023!**

2. Federico Bianchi*, Pratyusha Kalluri*, Esin Durmus*, Faisal Ladhak*, Myra Cheng*, Debora Nozza, Tatsunori Hashimoto, Dan Jurafsky, James Zou, Aylin Caliskan. Easily accessible text-to-image generation amplifies demographic stereotypes at large scale. ACM FAccT 2023. [[paper](https://arxiv.org/pdf/2211.03759.pdf?trk=public_post_comment-text)]

3. Myra Cheng, Maria De-Arteaga, Lester Mackey, and Adam Tauman Kalai. Social Norm Bias: Residual Harms of Fairness-Aware Algorithms. Data Mining and Knowledge Discovery 2023.
[[paper](https://arxiv.org/pdf/2108.11056.pdf)]

4. Weidinger, Laura, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng et al. Ethical and Social Risks of Harm from Language Models. ACM FAccT 2022. [[paper](https://dpmd.ai/llm-ethics)]

##### Full list of publications on [Google Scholar](https://scholar.google.com/citations?user=gaslQl8AAAAJ&hl=en) :) 
