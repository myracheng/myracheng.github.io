## Relevant Publications

1. Myra Cheng, Esin Durmus, Dan Jurafsky. [Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models.](https://arxiv.org/pdf/2305.18189.pdf) ACL 2023. <span style="color:#7BA6B7">Social Impact Award, Nominated for Best Paper</span>

2. Federico Bianchi\*, Pratyusha Kalluri\*, Esin Durmus\*, Faisal Ladhak\*, Myra Cheng\*, Debora Nozza, Tatsunori Hashimoto, Dan Jurafsky, James Zou, Aylin Caliskan. [Easily accessible text-to-image generation amplifies demographic stereotypes at large scale.](https://arxiv.org/pdf/2211.03759.pdf) ACM FAccT 2023.

3. Myra Cheng, Maria De-Arteaga, Lester Mackey, Adam Tauman Kalai. [Social Norm Bias: Residual Harms of Fairness-Aware Algorithms.](https://arxiv.org/pdf/2108.11056.pdf) Data Mining and Knowledge Discovery 2023.

4. Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng et al. [Ethical and Social Risks of Harm from Language Models.](https://arxiv.org/pdf/2112.04359.pdf) ACM FAccT 2022.

### Preprints
1. Pratyusha Ria Kalluri\*, William Agnew\*, Myra Cheng\*, Kentrell Owens\*, Luca Soldaini\*, Abeba Birhane\*. [The Surveillance AI Pipeline.](https://arxiv.org/pdf/2309.15084.pdf)

### Full list of publications on [Google Scholar](https://scholar.google.com/citations?user=gaslQl8AAAAJ&hl=en) :) 
