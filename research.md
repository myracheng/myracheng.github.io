## Relevant Publications

1. Myra Cheng, Esin Durmus, and Dan Jurafsky. [Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models.](https://arxiv.org/pdf/2305.18189.pdf) ACL 2023.
**Won the Social Impact Award at ACL 2023!**

2. Federico Bianchi\*, Pratyusha Kalluri\*, Esin Durmus\*, Faisal Ladhak\*, Myra Cheng\*, Debora Nozza, Tatsunori Hashimoto, Dan Jurafsky, James Zou, Aylin Caliskan. [Easily accessible text-to-image generation amplifies demographic stereotypes at large scale.](https://arxiv.org/pdf/2211.03759.pdf) ACM FAccT 2023.

3. Myra Cheng, Maria De-Arteaga, Lester Mackey, and Adam Tauman Kalai. [Social Norm Bias: Residual Harms of Fairness-Aware Algorithms.](https://arxiv.org/pdf/2108.11056.pdf) Data Mining and Knowledge Discovery 2023.

4. Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng et al. [Ethical and Social Risks of Harm from Language Models.](https://arxiv.org/pdf/2112.04359.pdf) ACM FAccT 2022.

### Full list of publications on [Google Scholar](https://scholar.google.com/citations?user=gaslQl8AAAAJ&hl=en) :) 
