## Publications

1. Myra Cheng, Tiziano Piccardi, Diyi Yang. [CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations.](https://arxiv.org/pdf/2310.11501.pdf) EMNLP 2023.

2. Myra Cheng, Esin Durmus, Dan Jurafsky. [Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models.](https://arxiv.org/pdf/2305.18189.pdf) ACL 2023. <span style="color:#7BA6B7">Social Impact Award, Nominated for Best Paper</span>

3. Federico Bianchi\*, Pratyusha Kalluri\*, Esin Durmus\*, Faisal Ladhak\*, Myra Cheng\*, Debora Nozza, Tatsunori Hashimoto, Dan Jurafsky, James Zou, Aylin Caliskan. [Easily accessible text-to-image generation amplifies demographic stereotypes at large scale.](https://arxiv.org/pdf/2211.03759.pdf) FAccT 2023. Press coverage in the [Washington Post](https://www.washingtonpost.com/technology/interactive/2023/ai-generated-images-bias-racism-sexism-stereotypes/) and [MIT Technology Review](https://www.technologyreview.com/2023/03/22/1070167/these-news-tool-let-you-see-for-yourself-how-biased-ai-image-models-are/).

4. Myra Cheng, Maria De-Arteaga, Lester Mackey, Adam Tauman Kalai. [Social Norm Bias: Residual Harms of Fairness-Aware Algorithms.](https://arxiv.org/pdf/2108.11056.pdf) Data Mining and Knowledge Discovery 2023.

5. Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng et al. [Ethical and Social Risks of Harm from Language Models.](https://arxiv.org/pdf/2112.04359.pdf) FAccT 2022.

### Preprints
1. Pratyusha Ria Kalluri\*, William Agnew\*, Myra Cheng\*, Kentrell Owens\*, Luca Soldaini\*, Abeba Birhane\*. [The Surveillance AI Pipeline.](https://arxiv.org/pdf/2309.15084.pdf)

### Also see [Semantic Scholar](https://www.semanticscholar.org/author/M.-Cheng/2149615775) & [Google Scholar](https://scholar.google.com/citations?user=gaslQl8AAAAJ&hl=en) :) 
